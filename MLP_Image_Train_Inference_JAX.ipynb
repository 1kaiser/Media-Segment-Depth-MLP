{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIqeYmcygU2ijsjhaiLpfO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/Media-Segment-Depth-MLP/blob/main/MLP_Image_Train_Inference_JAX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "miM9-4pMQ23h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Downloading the dataset**"
      ],
      "metadata": {
        "id": "99FCZgbz2SkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "download [flower dataset](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition?resource=download) from kaggle."
      ],
      "metadata": {
        "id": "go6vwNDjvoSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "!wget https://github.com/1kaiser/Media-Segment-Depth-MLP/releases/download/v0.2/archive.zip -O archive.zip\n",
        "!unzip /content/archive.zip #unzipping the flower images from archive..\n",
        "output.clear()\n",
        "##########################<< copying all varities into a single folder block >>################\n",
        "!mkdir -p /content/flowers/all\n",
        "!cp /content/flowers/daisy/* /content/flowers/all\n",
        "!cp /content/flowers/dandelion/* /content/flowers/all\n",
        "!cp /content/flowers/rose/* /content/flowers/all\n",
        "!cp /content/flowers/sunflower/* /content/flowers/all\n",
        "!cp /content/flowers/tulip/* /content/flowers/all\n",
        "##########################<< end of block >>################\n",
        "print(\"creating single image folder complete >>>\")\n"
      ],
      "metadata": {
        "id": "ZrgH9Bng9x_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RUN** "
      ],
      "metadata": {
        "id": "bwhvgI06xTIu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI1aeBA-dCqC"
      },
      "source": [
        "**Model and training code**\n",
        "Our model is a coordinate-based multilayer perceptron. In this example, for each input image coordinate $(x,y)$, the model predicts the associated color $(r,g,b)$ or any $(gray)$.\n",
        "\n",
        "![Network diagram](https://user-images.githubusercontent.com/3310961/85066930-ad444580-b164-11ea-9cc0-17494679e71f.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POSITIONAL ENCODING BLOCK** "
      ],
      "metadata": {
        "id": "cwyDAsz74bk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "positional_encoding_dims = 6  # Number of positional encodings applied\n",
        "\n",
        "def positional_encoding(args):\n",
        "    image_height_x_image_width, cha = args.shape\n",
        "    inputs_freq = jax.vmap(lambda x: args * 2.0 ** x)(jnp.arange(positional_encoding_dims))\n",
        "    x = jnp.stack([jnp.sin(inputs_freq), jnp.cos(inputs_freq)])\n",
        "    x = x.swapaxes(0, 2)\n",
        "    x = x.reshape([image_height_x_image_width, -1])\n",
        "    x = jnp.concatenate([args, x], axis=-1)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "z9aPWpu5iJ1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLP MODEL DEFINATION**\n",
        "Basically, passing input points through a simple Fourier Feature Mapping enables an MLP to learn high-frequency functions (such as an RGB image) in low-dimensional problem domains (such as a 2D coordinate of pixels)."
      ],
      "metadata": {
        "id": "DllYcUtgovO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "!python -m pip install -qq -U flax orbax\n",
        "# Orbax needs to enable asyncio in a Colab environment.\n",
        "!python -m pip install -qq nest_asyncio\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import flax\n",
        "import optax\n",
        "from typing import Any\n",
        "\n",
        "from jax import lax\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state, common_utils\n",
        "\n",
        "apply_positional_encoding = True # Apply posittional encoding to the input or not\n",
        "ndl = 8 # num_dense_layers Number of dense layers in MLP\n",
        "dlw = 256 # dense_layer_width Dimentionality of dense layers' output space \n",
        "\n",
        "##########################################<< MLP MODEL >>#########################################\n",
        "class MLPModel(nn.Module):\n",
        "    dtype: Any = jnp.float32\n",
        "    precision: Any = lax.Precision.DEFAULT\n",
        "    apply_positional_encoding: bool = apply_positional_encoding\n",
        "    @nn.compact\n",
        "    def __call__(self, input_points):\n",
        "        x = positional_encoding(input_points) if self.apply_positional_encoding else input_points\n",
        "        for i in range(ndl):\n",
        "            x = nn.Dense(dlw,dtype=self.dtype,precision=self.precision)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = jnp.concatenate([x, input_points], axis=-1) if i == 4 else x\n",
        "  \n",
        "        x = nn.Dense(1, dtype=self.dtype, precision=self.precision)(x)\n",
        "        return x\n",
        "##########################################<< MLP MODEL >>#########################################"
      ],
      "metadata": {
        "id": "VRkotxnvvHrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**initialize the module**"
      ],
      "metadata": {
        "id": "4o02pjAJqdjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "!python -m pip install -q -U flax\n",
        "import optax\n",
        "from flax.training import train_state\n",
        "import jax.numpy as jnp\n",
        "import jax\n",
        "\n",
        "\n",
        "def Create_train_state(r_key, model, shape, learning_rate ) -> train_state.TrainState:\n",
        "    print(shape)\n",
        "    variables = model.init(r_key, jnp.ones(shape)) \n",
        "    optimizer = optax.adam(learning_rate) \n",
        "    return train_state.TrainState.create(\n",
        "        apply_fn = model.apply,\n",
        "        tx=optimizer,\n",
        "        params=variables['params']\n",
        "    )\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size_no = 64\n",
        "\n",
        "model = MLPModel() # Instantiate the Model"
      ],
      "metadata": {
        "id": "rJEuhCl5xuR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**defining loss function**"
      ],
      "metadata": {
        "id": "ixrJnhFt4B2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#serial\n",
        "def image_difference_loss(logits, labels):\n",
        "    loss = .5 * jnp.mean((logits - labels) ** 2) \n",
        "    return loss\n",
        "def compute_metrics(*, logits, labels):\n",
        "  loss = image_difference_loss(logits, labels)\n",
        "  metrics = {\n",
        "      'loss': loss,     #LOSS\n",
        "      'logits': logits, #PREDICTED IMAGE\n",
        "      'labels': labels  #ACTUAL IMAGE\n",
        "  }\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "aAz8hjEbu2Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train step defination**"
      ],
      "metadata": {
        "id": "GAlchTpb3fVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cpu serial\n",
        "import jax\n",
        "\n",
        "def train_step(state: train_state.TrainState, batch: jnp.asarray, rng):\n",
        "    image, label = batch  \n",
        "    def loss_fn(params):\n",
        "        logits = state.apply_fn({'params': params}, image);\n",
        "        loss =  image_difference_loss(logits, label);\n",
        "        return loss, logits\n",
        "\n",
        "    gradient_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "    (_, logits), grads = gradient_fn(state.params)\n",
        "    new_state = state.apply_gradients(grads=grads)\n",
        "    logs = compute_metrics(logits=logits, labels=label)\n",
        "    return new_state, logs\n",
        "\n",
        "import jax\n",
        "@jax.jit\n",
        "def eval_step(state, image):\n",
        "    logits = state.apply_fn({'params': state.params}, image)\n",
        "    return compute_metrics(logits=logits, labels=image)\n"
      ],
      "metadata": {
        "id": "FJZR-rndueX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**image conversion fiunctions**"
      ],
      "metadata": {
        "id": "d-1nI5W-LN7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import jax.numpy as jnp\n",
        "def imageGRAY(argv):\n",
        "    im = Image.open(argv).convert('L')\n",
        "    tvt, tvu = jnp.asarray(im.resize(newsize)),jnp.asarray(im.resize(newsize)).reshape(-1,1)\n",
        "    return tvt, tvu\n",
        "def imageRGB(argv):\n",
        "    im = Image.open(argv)\n",
        "    tvt, tvu = jnp.asarray(im.resize(newsize)),jnp.asarray(im.resize(newsize)).reshape(-1,3)\n",
        "    return tvt, tvu"
      ],
      "metadata": {
        "id": "OF3ajPCGLSU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**image dataset, image size and batch size Setup**"
      ],
      "metadata": {
        "id": "Ns6S0Bmrxhyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########################################## to load the data in batches as mentioned single batch of images with already provided sizes \n",
        "import jax\n",
        "from jax import random\n",
        "\n",
        "newsize = (140,140) #(260, 260) # /.... 233 * 454\n",
        "batch_size = 1\n",
        "\n",
        "import os\n",
        "image_dir = r'/content/flowers/tulip/'\n",
        "#############################################################################\n",
        "bandend = [\"c\",\".jpg\", \"b02\"]\n",
        "expression_b2 = bandend[1]\n",
        "total_images =  [f for f in os.listdir(image_dir) if f.__contains__(expression_b2)]\n",
        "total_images.sort()\n",
        "total_images_path = [os.path.join(image_dir, i) for i in total_images if i != 'outputs']\n",
        "no_of_batches = int(len(total_images_path)/batch_size)\n",
        "\n",
        "######################################## making 8 array of input for each device >>>\n",
        "def batchedimages(image_locations):\n",
        "  RGB8 = jnp.asarray((imageRGB(total_images_path[image_locations[0]])[1]))\n",
        "  GRAY8 = jnp.asarray((imageGRAY(total_images_path[image_locations[0]])[1]))\n",
        "  batch_ccc = RGB8, GRAY8 \n",
        "  return batch_ccc\n",
        "\n",
        "def data_stream():\n",
        "  key = random.PRNGKey(0)\n",
        "  perm = random.permutation(key, len(total_images_path))\n",
        "  for i in range(no_of_batches):\n",
        "    batch_idx = perm[i * batch_size : (i + 1) * batch_size]; #print(batch_idx)\n",
        "    yield batchedimages(batch_idx)\n",
        "\n",
        "batches = data_stream()  "
      ],
      "metadata": {
        "id": "B7IgRCG91RcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **👠HIGH HEELS RUN >>>>>>>>>>>** { vertical-output: true }\n",
        "newsize = (140,140) #(260, 260) # /.... 233 * 454\n",
        "\n",
        "import jax\n",
        "from jax import random\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from google.colab import output\n",
        "import orbax.checkpoint as orbax\n",
        "from flax.training import checkpoints\n",
        "\n",
        "import optax\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "rng = jax.random.PRNGKey(0)\n",
        "CKPT_DIR = 'ckpts'\n",
        "\n",
        "######################<<<< initiating train state\n",
        "count = 0\n",
        "if count == 0 :\n",
        "  HxW, Channels = next(batches)[0].shape\n",
        "  state = Create_train_state( rng, model, (HxW, Channels), learning_rate ) \n",
        "  count = 1\n",
        "#✅✅🔻 state = flax.jax_utils.replicate(state)  # FLAX will replicate the state to every device so that updating can be made easy\n",
        "\n",
        "###################### \n",
        "checkpoint_available = 0\n",
        "pattern = re.compile(\"checkpoint_\\d+\")   # to search for \"checkpoint_*munerical value*\" numerical value of any length is denoted by regular expression \"\\d+\"\n",
        "dir = \"/content/ckpts/\"\n",
        "isFile = os.path.isdir(dir)\n",
        "if isFile:\n",
        "  for filepath in os.listdir(dir):\n",
        "      if pattern.match(filepath):\n",
        "          checkpoint_available = 1\n",
        "\n",
        "total_epochs = 50\n",
        "for epochs in tqdm(range(total_epochs)):  \n",
        "  batches = data_stream() \n",
        "\n",
        "  if checkpoint_available:\n",
        "    state = checkpoints.restore_checkpoint(ckpt_dir=CKPT_DIR, target=state)\n",
        "    checkpoint_available = 0 # << Flag updated >>> to stop loading the same checkpoint in the next iteration then remove the checkpoint directory\n",
        "    !rm -r {dir}\n",
        "\n",
        "  for bbb in tqdm(range(no_of_batches-5)):\n",
        "    state, metrics = train_step(state, next(batches), rng)\n",
        "    output.clear()\n",
        "    print(\"loss: \",metrics['loss'],\" <<< \") # naming of the checkpoint is \"checkpoint_*\"  where \"*\" => value of the steps variable, i.e. 'epochs'\n",
        "  orbax_checkpointer = orbax.Checkpointer(orbax.PyTreeCheckpointHandler())\n",
        "  checkpoints.save_checkpoint(ckpt_dir=CKPT_DIR, target=state, step=epochs, prefix='checkpoint_', keep=1, overwrite=False, orbax_checkpointer=orbax_checkpointer)\n",
        "  # restored_state = checkpoints.restore_checkpoint(ckpt_dir=CKPT_DIR, target=state) # using to get the checkpoint loaded , it can be latest one , or if already available as checkpoint in the \"CKPT_DIR\" directory then take the file from directory then save in >> restored_checkpoints\n",
        "  ##################################################\n",
        "\n"
      ],
      "metadata": {
        "id": "TH4A--qI31lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**inference engine**"
      ],
      "metadata": {
        "id": "YchphIIkJIf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# newsize = (140,140) #(260, 260) # /.... 233 * 454\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np \n",
        "from google.colab import output\n",
        "from flax.training import checkpoints\n",
        "\n",
        "!wget https://live.staticflickr.com/7492/15677707699_d9d67acf9d_b.jpg -O a.jpg\n",
        "image_in = '/content/a.jpg'\n",
        "\n",
        "from PIL import Image\n",
        "import jax.numpy as jnp\n",
        "def imageRGB(argv):\n",
        "    im = Image.open(argv)\n",
        "    tvt, tvu = jnp.asarray(im.resize(newsize)),jnp.asarray(im.resize(newsize)).reshape(-1,3)\n",
        "    return tvt, tvu\n",
        "image = jnp.asarray((imageRGB(image_in)[1]))\n",
        "#restored_state = checkpoints.restore_checkpoint(ckpt_dir=CKPT_DIR, target=state)\n",
        "#state = restored_state\n",
        "#initialize\n",
        "HxW, Channels = image.shape\n",
        "state = Create_train_state( model, rng, (HxW, Channels), learning_rate ) \n",
        "\n",
        "state = checkpoints.restore_checkpoint(ckpt_dir=CKPT_DIR, target=state)\n",
        "prediction = eval_step(state, image)\n",
        "prediction['loss']\n",
        "\n",
        "\n",
        "predicted_image = np.array(prediction['logits'],  dtype=np.uint8).reshape(newsize) \n",
        "cv2_imshow(predicted_image)\n"
      ],
      "metadata": {
        "id": "VmZn4n_-JL-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# import numpy as np \n",
        "# def show_image(argu):\n",
        "#   L1 = argu[0]\n",
        "#   predicted_image = np.array(argu[0],  dtype=np.uint8).reshape(newsize) # This would be your image array\n",
        "#   a = predicted_image\n",
        "#   for i in range(0,argu.shape[0]):\n",
        "#     predicted_image = np.array(argu[i],  dtype=np.uint8).reshape(newsize) \n",
        "#     a = cv2.hconcat([a, predicted_image])\n",
        "#   cv2_imshow(a)\n",
        "\n",
        "# show_image(metrics['logits'])"
      ],
      "metadata": {
        "id": "teuUnNYweNNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from jax.tree_util import tree_structure\n",
        "# print(tree_structure(state))"
      ],
      "metadata": {
        "id": "LOK4VpYK53ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**test dataset segmentation Creation download section**"
      ],
      "metadata": {
        "id": "79e1MnTEOiYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################<<< MEDIAPIPE LIBRARY INSTALLATON >>>#############################\n",
        "!python -m pip install mediapipe\n",
        "##################################<<< FRAME EXTRACTION >>>#############################\n",
        "video_location = '/content/drive/MyDrive/OUT/data/machine_learning_test_dataset/test.mp4'\n",
        "import os\n",
        "\n",
        " \n",
        "# Read images with OpenCV.\n",
        "#images= None\n",
        "image_dir = '/content/MEDIAPIPEinput/'\n",
        "os.makedirs(image_dir, exist_ok=True)\n",
        "image_dir_out = '/content/annotated_images'\n",
        "os.makedirs(image_dir_out, exist_ok=True)\n",
        "frame_rate = 25\n",
        "!ffmpeg -y -hwaccel cuvid \\\n",
        "  -i {video_location} \\\n",
        "  -r {frame_rate} {image_dir}out_%09d.png\n",
        "\n",
        "imgs_list = os.listdir(image_dir)\n",
        "imgs_list.sort()\n",
        "imgs_path = [os.path.join(image_dir, i) for i in imgs_list if i != 'outputs']\n",
        "################################<<< SEGMENTATION USING MEDIAPIPE >>>###################################\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "# mp_holistic = mp.solutions.holistic\n",
        "mp_pose = mp.solutions.pose\n",
        "!rm -r {image_dir}.ipynb_checkpoints\n",
        "\n",
        "# Run MediaPipe Pose with `enable_segmentation=True` to get pose segmentation.\n",
        "with mp_pose.Pose(static_image_mode=True, \n",
        "                          min_detection_confidence=0.2,\n",
        "                          model_complexity=2, \n",
        "                          enable_segmentation=True,) as pose:\n",
        "  temp_segmentation_mask =[]                        \n",
        "  for name, image in enumerate(imgs_path):\n",
        "    !rm -r {image_dir}.ipynb_checkpoints\n",
        "    # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
        "    image = cv2.imread(image)\n",
        "    results = pose.process(image)\n",
        "\n",
        "    # Draw pose segmentation.\n",
        "    print(f'Pose segmentation of {name}:')\n",
        "    annotated_image_pose = image.copy()\n",
        "    red_img = np.zeros_like(annotated_image_pose, dtype=np.uint8)\n",
        "    red_img[:, :] = (255,255,255)\n",
        "    ###check if segmentation_mask exists or not ## if exists then ok Else use previous mask temporarily\n",
        "    if results.segmentation_mask is None:\n",
        "      print(\"true\")\n",
        "      results.segmentation_mask = temp_segmentation_mask[-1]\n",
        "      temp_segmentation_mask.append(results.segmentation_mask)\n",
        "    else:\n",
        "      temp_segmentation_mask.append(results.segmentation_mask)\n",
        "    ###End check if segmentation_mask exists or not ## if exists then ok Else use previous mask temporarily\n",
        "    segm_2class = 0.0 + 1.0 * results.segmentation_mask\n",
        "    segm_2class = np.repeat(segm_2class[..., np.newaxis], 3, axis=2)\n",
        "    annotated_image_pose = annotated_image_pose * segm_2class + red_img * (1 - segm_2class)\n",
        "    #resize_and_show(annotated_image)\n",
        "    cv2.imwrite('%s/%s' %(image_dir_out, imgs_list[name]), annotated_image_pose)\n",
        "    !rm -r {image_dir_out}.ipynb_checkpoints\n"
      ],
      "metadata": {
        "id": "T-5VcETfQAR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RUN 2** "
      ],
      "metadata": {
        "id": "vtbymxQuOcXW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3-r9u0POcXX"
      },
      "source": [
        "**Model and training code**\n",
        "Our model is a coordinate-based multilayer perceptron. In this example, for each input image coordinate $(x,y)$, the model predicts the associated color $(r,g,b)$ or any $(gray)$.\n",
        "\n",
        "![Network diagram](https://user-images.githubusercontent.com/3310961/85066930-ad444580-b164-11ea-9cc0-17494679e71f.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POSITIONAL ENCODING BLOCK** "
      ],
      "metadata": {
        "id": "Ya1v16NLOcXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "positional_encoding_dims = 6  # Number of positional encodings applied\n",
        "\n",
        "def positional_encoding(args):\n",
        "    image_height_x_image_width, cha = args.shape\n",
        "    inputs_freq = jax.vmap(lambda x: args * 2.0 ** x)(jnp.arange(positional_encoding_dims))\n",
        "    x = jnp.stack([jnp.sin(inputs_freq), jnp.cos(inputs_freq)])\n",
        "    x = x.swapaxes(0, 2)\n",
        "    x = x.reshape([image_height_x_image_width, -1])\n",
        "    x = jnp.concatenate([args, x], axis=-1)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "WHJKNAuvOcXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLP MODEL DEFINATION**\n",
        "Basically, passing input points through a simple Fourier Feature Mapping enables an MLP to learn high-frequency functions (such as an RGB image) in low-dimensional problem domains (such as a 2D coordinate of pixels)."
      ],
      "metadata": {
        "id": "Wfdc8fraOcXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "!python -m pip install -qq -U flax orbax\n",
        "# Orbax needs to enable asyncio in a Colab environment.\n",
        "!python -m pip install -qq nest_asyncio\n",
        "\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import flax\n",
        "import optax\n",
        "from typing import Any\n",
        "\n",
        "from jax import lax\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state, common_utils\n",
        "\n",
        "apply_positional_encoding = True # Apply posittional encoding to the input or not\n",
        "ndl = 8 # num_dense_layers Number of dense layers in MLP\n",
        "dlw = 256 # dense_layer_width Dimentionality of dense layers' output space \n",
        "\n",
        "##########################################<< MLP MODEL >>#########################################\n",
        "class MLPModel(nn.Module):\n",
        "    dtype: Any = jnp.float32\n",
        "    precision: Any = lax.Precision.DEFAULT\n",
        "    apply_positional_encoding: bool = apply_positional_encoding\n",
        "    @nn.compact\n",
        "    def __call__(self, input_points):\n",
        "        x = positional_encoding(input_points) if self.apply_positional_encoding else input_points\n",
        "        for i in range(ndl):\n",
        "            x = nn.Dense(dlw,dtype=self.dtype,precision=self.precision)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = jnp.concatenate([x, input_points], axis=-1) if i == 4 else x\n",
        "  \n",
        "        x = nn.Dense(1, dtype=self.dtype, precision=self.precision)(x)\n",
        "        return x\n",
        "##########################################<< MLP MODEL >>#########################################"
      ],
      "metadata": {
        "id": "fBWJpWQ-OcXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**initialize the module**"
      ],
      "metadata": {
        "id": "Uy5pjMvjOcXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "!python -m pip install -q -U flax\n",
        "import optax\n",
        "from flax.training import train_state\n",
        "import jax.numpy as jnp\n",
        "import jax\n",
        "\n",
        "\n",
        "def Create_train_state(r_key, model, shape, learning_rate ) -> train_state.TrainState:\n",
        "    print(shape)\n",
        "    variables = model.init(r_key, jnp.ones(shape)) \n",
        "    optimizer = optax.adam(learning_rate) \n",
        "    return train_state.TrainState.create(\n",
        "        apply_fn = model.apply,\n",
        "        tx=optimizer,\n",
        "        params=variables['params']\n",
        "    )\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size_no = 64\n",
        "\n",
        "model = MLPModel() # Instantiate the Model"
      ],
      "metadata": {
        "id": "qlst_jMhOcXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**defining loss function**"
      ],
      "metadata": {
        "id": "nk7vrtd1OcXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#serial\n",
        "def image_difference_loss(logits, labels):\n",
        "    loss = .5 * jnp.mean((logits - labels) ** 2) \n",
        "    return loss\n",
        "def compute_metrics(*, logits, labels):\n",
        "  loss = image_difference_loss(logits, labels)\n",
        "  metrics = {\n",
        "      'loss': loss,     #LOSS\n",
        "      'logits': logits, #PREDICTED IMAGE\n",
        "      'labels': labels  #ACTUAL IMAGE\n",
        "  }\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "BdL-XGU2OcXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train step defination**"
      ],
      "metadata": {
        "id": "YM0w1GDhOcXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cpu serial\n",
        "import jax\n",
        "\n",
        "def train_step(state: train_state.TrainState, batch: jnp.asarray, rng):\n",
        "    image, label = batch  \n",
        "    def loss_fn(params):\n",
        "        logits = state.apply_fn({'params': params}, image);\n",
        "        loss =  image_difference_loss(logits, label);\n",
        "        return loss, logits\n",
        "\n",
        "    gradient_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "    (_, logits), grads = gradient_fn(state.params)\n",
        "    new_state = state.apply_gradients(grads=grads)\n",
        "    logs = compute_metrics(logits=logits, labels=label)\n",
        "    return new_state, logs\n",
        "\n",
        "import jax\n",
        "@jax.jit\n",
        "def eval_step(state, image):\n",
        "    logits = state.apply_fn({'params': state.params}, image)\n",
        "    return compute_metrics(logits=logits, labels=image)\n"
      ],
      "metadata": {
        "id": "ahpb0DxBOcXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**image conversion fiunctions**"
      ],
      "metadata": {
        "id": "wHKiqTxCOcXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import jax.numpy as jnp\n",
        "def imageGRAY(argv):\n",
        "    im = Image.open(argv).convert('L')\n",
        "    tvt, tvu = jnp.asarray(im.resize(newsize)),jnp.asarray(im.resize(newsize)).reshape(-1,1)\n",
        "    return tvt, tvu\n",
        "def imageRGB(argv):\n",
        "    im = Image.open(argv)\n",
        "    tvt, tvu = jnp.asarray(im.resize(newsize)),jnp.asarray(im.resize(newsize)).reshape(-1,3)\n",
        "    return tvt, tvu"
      ],
      "metadata": {
        "id": "rxbefKzwOcXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**image dataset, image size and batch size Setup**"
      ],
      "metadata": {
        "id": "plbG5Hx5OcXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########################################## to load the data in batches as mentioned single batch of images with already provided sizes \n",
        "import jax\n",
        "from jax import random\n",
        "\n",
        "newsize = (140,140) #(260, 260) # /.... 233 * 454\n",
        "batch_size = 1\n",
        "\n",
        "import os\n",
        "image_dir = r'/content/MEDIAPIPEinput'\n",
        "annotated_image_dir = r'/content/annotated_images'\n",
        "\n",
        "#############################################################################\n",
        "bandend = [\"c\",\".png\", \"b02\"]\n",
        "expression_b2 = bandend[1]\n",
        "\n",
        "total_images =  [f for f in os.listdir(image_dir) if f.__contains__(expression_b2)]\n",
        "total_images.sort()\n",
        "total_images_path = [os.path.join(image_dir, i) for i in total_images if i != 'outputs']\n",
        "\n",
        "annotated_total_images =  [f for f in os.listdir(annotated_image_dir) if f.__contains__(expression_b2)]\n",
        "annotated_total_images.sort()\n",
        "annotated_total_images_path = [os.path.join(annotated_image_dir, i) for i in annotated_total_images if i != 'outputs']\n",
        "\n",
        "no_of_batches = int(len(total_images_path)/batch_size)\n",
        "\n",
        "######################################## making 8 array of input for each device >>>\n",
        "def batchedimages(image_locations):\n",
        "  RGB8 = jnp.asarray((imageRGB(total_images_path[image_locations[0]])[1]))\n",
        "  ANNOTATED8 = jnp.asarray((imageRGB(annotated_total_images_path[image_locations[0]])[1]))\n",
        "  batch_ccc = RGB8, ANNOTATED8 \n",
        "  return batch_ccc\n",
        "\n",
        "def data_stream():\n",
        "  key = random.PRNGKey(0)\n",
        "  perm = random.permutation(key, len(total_images_path))\n",
        "  for i in range(no_of_batches):\n",
        "    batch_idx = perm[i * batch_size : (i + 1) * batch_size]; #print(batch_idx)\n",
        "    yield batchedimages(batch_idx)\n",
        "\n",
        "batches = data_stream()  "
      ],
      "metadata": {
        "id": "qjCNWEP9OcXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(batches)[0].shape"
      ],
      "metadata": {
        "id": "PUh2xVp4S6ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **👠HIGH HEELS RUN >>>>>>>>>>>** { vertical-output: true }\n",
        "newsize = (140,140) #(260, 260) # /.... 233 * 454\n",
        "\n",
        "import jax\n",
        "from jax import random\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from google.colab import output\n",
        "import orbax.checkpoint as orbax\n",
        "from flax.training import checkpoints\n",
        "\n",
        "import optax\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "rng = jax.random.PRNGKey(0)\n",
        "CKPT_DIR = 'ckpts'\n",
        "\n",
        "######################<<<< initiating train state\n",
        "count = 0\n",
        "if count == 0 :\n",
        "  HxW, Channels = next(batches)[0].shape\n",
        "  state = Create_train_state( rng, model, (HxW, Channels), learning_rate ) \n",
        "  count = 1\n",
        "#✅✅🔻 state = flax.jax_utils.replicate(state)  # FLAX will replicate the state to every device so that updating can be made easy\n",
        "\n",
        "###################### \n",
        "checkpoint_available = 0\n",
        "pattern = re.compile(\"checkpoint_\\d+\")   # to search for \"checkpoint_*munerical value*\" numerical value of any length is denoted by regular expression \"\\d+\"\n",
        "dir = \"/content/ckpts/\"\n",
        "isFile = os.path.isdir(dir)\n",
        "if isFile:\n",
        "  for filepath in os.listdir(dir):\n",
        "      if pattern.match(filepath):\n",
        "          checkpoint_available = 1\n",
        "\n",
        "total_epochs = 50\n",
        "for epochs in tqdm(range(total_epochs)):  \n",
        "  batches = data_stream() \n",
        "\n",
        "  if checkpoint_available:\n",
        "    state = checkpoints.restore_checkpoint(ckpt_dir=CKPT_DIR, target=state)\n",
        "    checkpoint_available = 0 # << Flag updated >>> to stop loading the same checkpoint in the next iteration then remove the checkpoint directory\n",
        "    !rm -r {dir}\n",
        "\n",
        "  for bbb in tqdm(range(no_of_batches-5)):\n",
        "    state, metrics = train_step(state, next(batches), rng)\n",
        "    output.clear()\n",
        "    print(\"loss: \",metrics['loss'],\" <<< \") # naming of the checkpoint is \"checkpoint_*\"  where \"*\" => value of the steps variable, i.e. 'epochs'\n",
        "  orbax_checkpointer = orbax.Checkpointer(orbax.PyTreeCheckpointHandler())\n",
        "  checkpoints.save_checkpoint(ckpt_dir=CKPT_DIR, target=state, step=epochs, prefix='checkpoint_', keep=1, overwrite=False, orbax_checkpointer=orbax_checkpointer)\n",
        "  # restored_state = checkpoints.restore_checkpoint(ckpt_dir=CKPT_DIR, target=state) # using to get the checkpoint loaded , it can be latest one , or if already available as checkpoint in the \"CKPT_DIR\" directory then take the file from directory then save in >> restored_checkpoints\n",
        "  ##################################################\n",
        "\n"
      ],
      "metadata": {
        "id": "LakSOVw3OcXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**inference engine**"
      ],
      "metadata": {
        "id": "iE4IPvggOcXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# newsize = (140,140) #(260, 260) # /.... 233 * 454\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np \n",
        "from google.colab import output\n",
        "\n",
        "!wget https://live.staticflickr.com/7492/15677707699_d9d67acf9d_b.jpg -O a.jpg\n",
        "image_in = '/content/a.jpg'\n",
        "\n",
        "from PIL import Image\n",
        "import jax.numpy as jnp\n",
        "def imageRGB(argv):\n",
        "    im = Image.open(argv)\n",
        "    tvt, tvu = jnp.asarray(im.resize(newsize)),jnp.asarray(im.resize(newsize)).reshape(-1,3)\n",
        "    return tvt, tvu\n",
        "image = jnp.asarray((imageRGB(image_in)[1]))\n",
        "#restored_state = checkpoints.restore_checkpoint(ckpt_dir=CKPT_DIR, target=state)\n",
        "#state = restored_state\n",
        "prediction = eval_step(state, image)\n",
        "prediction['loss']\n",
        "\n",
        "\n",
        "predicted_image = np.array(prediction['logits'],  dtype=np.uint8).reshape(newsize) \n",
        "cv2_imshow(predicted_image)\n"
      ],
      "metadata": {
        "id": "VAmef9UcOcXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# import numpy as np \n",
        "# def show_image(argu):\n",
        "#   L1 = argu[0]\n",
        "#   predicted_image = np.array(argu[0],  dtype=np.uint8).reshape(newsize) # This would be your image array\n",
        "#   a = predicted_image\n",
        "#   for i in range(0,argu.shape[0]):\n",
        "#     predicted_image = np.array(argu[i],  dtype=np.uint8).reshape(newsize) \n",
        "#     a = cv2.hconcat([a, predicted_image])\n",
        "#   cv2_imshow(a)\n",
        "\n",
        "# show_image(metrics['logits'])"
      ],
      "metadata": {
        "id": "ejRwflrdOcXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from jax.tree_util import tree_structure\n",
        "# print(tree_structure(state))"
      ],
      "metadata": {
        "id": "VYrnNTEpOcXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**ensemble**"
      ],
      "metadata": {
        "id": "ka3_468K9xRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "!python -m pip install -q -U flax\n",
        "from typing import Any\n",
        "import jax\n",
        "from jax import lax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state, common_utils\n",
        "import functools\n",
        "\n",
        "positional_encoding_dims = 6  # Number of positional encodings applied\n",
        "\n",
        "def positional_encoding(args):\n",
        "    image_height_x_image_width, cha = args.shape\n",
        "    inputs_freq = jax.vmap(lambda x: args * 2.0 ** x)(jnp.arange(positional_encoding_dims))\n",
        "    x = jnp.stack([jnp.sin(inputs_freq), jnp.cos(inputs_freq)])\n",
        "    x = x.swapaxes(0, 2)\n",
        "    x = x.reshape([image_height_x_image_width, -1])\n",
        "    x = jnp.concatenate([args, x], axis=-1)\n",
        "    return x\n",
        "\n",
        "apply_positional_encoding = True # Apply posittional encoding to the input or not\n",
        "ndl = 8 # num_dense_layers Number of dense layers in MLP\n",
        "dlw = 256 # dense_layer_width Dimentionality of dense layers' output space \n",
        "\n",
        "##########################################<< MLP MODEL >>#########################################\n",
        "class MLPModel(nn.Module):\n",
        "    dtype: Any = jnp.float32\n",
        "    precision: Any = lax.Precision.DEFAULT\n",
        "    apply_positional_encoding: bool = apply_positional_encoding\n",
        "    @nn.compact\n",
        "    def __call__(self, input_points):\n",
        "        x = positional_encoding(input_points) if self.apply_positional_encoding else input_points\n",
        "        for i in range(ndl):\n",
        "            x = nn.Dense(dlw,dtype=self.dtype,precision=self.precision)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = jnp.concatenate([x, input_points], axis=-1) if i == 4 else x\n",
        "  \n",
        "        x = nn.Dense(1, dtype=self.dtype, precision=self.precision)(x)\n",
        "        return x\n",
        "##########################################<< MLP MODEL >>#########################################\n",
        "\n",
        "@functools.partial(jax.pmap, static_broadcasted_argnums=(1, 2))\n",
        "def Create_train_state(r_key, shape, learning_rate ):\n",
        "    print(shape)\n",
        "    model = MLPModel()\n",
        "    variables = model.init(r_key, jnp.ones(shape)) \n",
        "    optimizer = optax.adam(learning_rate) \n",
        "    return train_state.TrainState.create(\n",
        "        apply_fn = model.apply,\n",
        "        tx=optimizer,\n",
        "        params=variables['params']\n",
        "    )\n",
        "\n",
        "# learning_rate = 1e-4\n",
        "# batch_size_no = 64\n",
        "\n",
        "# model = MLPModel() # Instantiate the Model"
      ],
      "metadata": {
        "id": "Aaat0R0q9Z7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@functools.partial(jax.pmap, axis_name='ensemble')\n",
        "def apply_model(state, batch: jnp.asarray):\n",
        "  image, label = batch\n",
        "  def loss_fn(params):\n",
        "    logits = MLPModel().apply({'params': params}, image)\n",
        "    loss =  image_difference_loss(logits, label);\n",
        "    return loss, logits\n",
        "\n",
        "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  (loss, logits), grads = grad_fn(state.params)\n",
        "  return grads, loss\n",
        "\n",
        "@jax.pmap\n",
        "def update_model(state, grads):\n",
        "  return state.apply_gradients(grads=grads)"
      ],
      "metadata": {
        "id": "QyGP4Fmf-q7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(state, train_ds, batch_size, rng):\n",
        "  train_ds_size = len(train_ds['image'])\n",
        "  steps_per_epoch = train_ds_size // batch_size\n",
        "\n",
        "  perms = jax.random.permutation(rng, len(train_ds['image']))\n",
        "  perms = perms[:steps_per_epoch * batch_size]\n",
        "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
        "\n",
        "  epoch_loss = []\n",
        "\n",
        "  for perm in perms:\n",
        "    batch_images = jax_utils.replicate(train_ds['image'][perm, ...])\n",
        "    batch_labels = jax_utils.replicate(train_ds['label'][perm, ...])\n",
        "    grads, loss = apply_model(state, batch_images, batch_labels)\n",
        "    state = update_model(state, grads)\n",
        "    epoch_loss.append(jax_utils.unreplicate(loss))\n",
        "  train_loss = np.mean(epoch_loss)\n",
        "  return state, train_loss"
      ],
      "metadata": {
        "id": "QQUj3Y3LA9A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, test_ds = get_datasets()\n",
        "test_ds = jax_utils.replicate(test_ds)\n",
        "rng = jax.random.PRNGKey(0)\n",
        "\n",
        "rng, init_rng = jax.random.split(rng)\n",
        "\n",
        "HxW, Channels = next(batches)[0].shape\n",
        "state = create_train_state(jax.random.split(init_rng, jax.device_count()),(HxW, Channels),learning_rate)\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  rng, input_rng = jax.random.split(rng)\n",
        "  state, train_loss = train_epoch(state, train_ds, batch_size, input_rng)\n",
        "\n",
        "  # _, test_loss = jax_utils.unreplicate(apply_model(state, test_ds['image'], test_ds['label']))\n",
        "\n",
        "  logging.info('epoch:% 3d, train_loss: %.4f ' % (epoch, train_loss))"
      ],
      "metadata": {
        "id": "X-CttLscBnDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# same as before, but using @pad_shard_unshard decorator\n",
        "\n",
        "# manually padding\n",
        "# => precise & allows for data parallelism\n",
        "\n",
        "@jax.pmap\n",
        "def get_preds(variables, inputs):\n",
        "  print('retrigger compilation', inputs.shape)\n",
        "  return model.apply(variables, inputs)\n",
        "\n",
        "ds = tfds.load(dataset_name, split=tfds.split_for_jax_process('test'))\n",
        "per_host_batch_size = per_device_batch_size * jax.local_device_count()\n",
        "ds = ds.batch(per_host_batch_size, drop_remainder=False)\n",
        "\n",
        "correct = total = 0\n",
        "for batch in ds.as_numpy_iterator():\n",
        "  preds = flax.jax_utils.pad_shard_unpad(get_preds)(\n",
        "      vs, batch['image'], min_device_batch=per_device_batch_size)\n",
        "  total += len(batch['image'])\n",
        "  correct += (batch['label'] == preds.argmax(axis=-1)).sum()\n",
        "\n",
        "correct = correct.item()\n",
        "correct, total, correct / total"
      ],
      "metadata": {
        "id": "I_orMqbuD3LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_step(metrics, variables, batch):\n",
        "  print('retrigger compilation', {k: v.shape for k, v in batch.items()})\n",
        "  preds = model.apply(variables, batch['image'])\n",
        "  correct = (batch['mask'] & (batch['label'] == preds.argmax(axis=-1))).sum()\n",
        "  total = batch['mask'].sum()\n",
        "  return dict(\n",
        "      correct=metrics['correct'] + jax.lax.psum(correct, axis_name='batch'),\n",
        "      total=metrics['total'] + jax.lax.psum(total, axis_name='batch'),\n",
        "  )\n",
        "\n",
        "eval_step = jax.pmap(eval_step, axis_name='batch')\n",
        "eval_step = flax.jax_utils.pad_shard_unpad(\n",
        "    eval_step, static_argnums=(0, 1), static_return=True)"
      ],
      "metadata": {
        "id": "RxhJjRZLD5P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {total_files}\n",
        "%cd ..\n",
        "!zip -r folder.zip {total_files}"
      ],
      "metadata": {
        "id": "9PboYgRwzhb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/folder.zip /content/drive/MyDrive/OUT/data/machine_learning_test_dataset"
      ],
      "metadata": {
        "id": "N_Mbj-WH0raq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/1kaiser/Media-Segment-Depth-MLP/releases/download/v0.2/s.zip"
      ],
      "metadata": {
        "id": "dF77PT3FHZ3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/s.zip #unzipping the flower images from archive.."
      ],
      "metadata": {
        "id": "vImC4C6oHeRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_files= '/content/s'\n",
        "input_images = '/content/MEDIAPIPEinput'\n",
        "out_images = '/content/annotated_images'\n",
        "!mkdir -p {total_files}\n",
        "!cp -r {input_images} {total_files}\n",
        "!cp -r {out_images} {total_files}"
      ],
      "metadata": {
        "id": "FsMi1Ce8xX0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {total_files}\n",
        "!tfds new my_dataset"
      ],
      "metadata": {
        "id": "vRFhGL28yCvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_files= '/content/s'\n",
        "%cd {total_files}/my_dataset/\n",
        "!tfds build"
      ],
      "metadata": {
        "id": "KX-D3ii8yRFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/t/my_dataset"
      ],
      "metadata": {
        "id": "0ODocGRg82Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def _generate_examples(self, path):\n",
        "  \"\"\"Yields examples.\"\"\"\n",
        "  # TODO(my_dataset): Yields (key, example) tuples from the dataset\n",
        "  for f in path.glob('*.png'):\n",
        "    yield 'key', {\n",
        "        'MEDIAPIPEinput': f,\n",
        "        'annotated_images': f,\n",
        "    }\n",
        "    \n",
        "os.path = r'/content/s'\n",
        "_generate_examples(path / 'MEDIAPIPEinput')"
      ],
      "metadata": {
        "id": "oEUwsD8Q4uS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "dl_manager = tfds.download.DownloadManager(download_dir='/content')\n",
        "urls = 'https://github.com/1kaiser/Media-Segment-Depth-MLP/releases/download/v0.2/s.zip'\n",
        "path = dl_manager.extract(dl_manager.download(urls))"
      ],
      "metadata": {
        "id": "-2d0H4Yh97iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _generate_examples( img_path):\n",
        "  # Read the input data out of the source files\n",
        "  # with img_path.open() as f:\n",
        "    yield {\n",
        "        'image': img_path / '*.png',\n",
        "    }\n",
        "\n",
        "def _split_generators():\n",
        "    \"\"\"Download the data and define splits.\"\"\"\n",
        "    dl_manager = tfds.download.DownloadManager(download_dir='/content')\n",
        "    urls = 'https://github.com/1kaiser/Media-Segment-Depth-MLP/releases/download/v0.2/s.zip'\n",
        "    path = dl_manager.extract(dl_manager.download(urls))    # dl_manager returns pathlib-like objects with `path.read_text()`,\n",
        "    # `path.iterdir()`,...\n",
        "    return {\n",
        "        'in_image': _generate_examples(path / 'MEDIAPIPEinput'),\n",
        "        'out_image': _generate_examples(path / 'annotated_images'),\n",
        "    }\n",
        "# _generate_examples(path/'MEDIAPIPEinput')\n",
        "print(_split_generators()['in_image'])"
      ],
      "metadata": {
        "id": "Q7fq5IunA5-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(path)"
      ],
      "metadata": {
        "id": "QkHMo5itRsIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(_generate_examples(path / 'MEDIAPIPEinput'))['image']"
      ],
      "metadata": {
        "id": "SnxXUYPSX2Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Builder(tfds.core.GeneratorBasedBuilder):\n",
        "  \"\"\"DatasetBuilder for my_dataset dataset.\"\"\"\n",
        "\n",
        "  VERSION = tfds.core.Version('1.0.0')\n",
        "  RELEASE_NOTES = {\n",
        "      '1.0.0': 'Initial release.',\n",
        "  }\n",
        "\n",
        "  def _info(self) -> tfds.core.DatasetInfo:\n",
        "    \"\"\"Dataset metadata (homepage, citation,...).\"\"\"\n",
        "    return self.dataset_info_from_configs(\n",
        "        features=tfds.features.FeaturesDict({\n",
        "            'image': tfds.features.Image(shape=(256, 256, 3)),\n",
        "            'label': tfds.features.Image(shape=(256, 256, 3)),\n",
        "        }),\n",
        "    )\n",
        "\n",
        "  def _split_generators(self, dl_manager: tfds.download.DownloadManager):\n",
        "    \"\"\"Download the data and define splits.\"\"\"\n",
        "    urls = 'https://github.com/1kaiser/Media-Segment-Depth-MLP/releases/download/v0.2/s.zip'\n",
        "    extracted_path = dl_manager.download_and_extract(urls)\n",
        "    # dl_manager returns pathlib-like objects with `path.read_text()`,\n",
        "    # `path.iterdir()`,...\n",
        "    return {\n",
        "        'train': self._generate_input_examples(path=extracted_path / 'MEDIAPIPEinput'),\n",
        "        'test': self._generate_output_examples(path=extracted_path / 'annotated_images'),\n",
        "    }\n",
        "\n",
        "  def _generate_input_examples(self, path) -> Iterator[Tuple[Key, Example]]:\n",
        "    \"\"\"Generator of examples for each split.\"\"\"\n",
        "    for img_path in path.glob('*.png'):\n",
        "      # Yields (key, example)\n",
        "      yield img_path.name, {\n",
        "          'image': img_path,\n",
        "      }\n",
        "  def _generate_output_examples(self, path) -> Iterator[Tuple[Key, Example]]:\n",
        "    \"\"\"Generator of examples for each split.\"\"\"\n",
        "    for img_path in path.glob('*.png'):\n",
        "      # Yields (key, example)\n",
        "      yield img_path.name, {\n",
        "          'image': img_path,\n",
        "      }"
      ],
      "metadata": {
        "id": "inwnL9-tGNT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the modules\n",
        "import os\n",
        "from os import listdir\n",
        " \n",
        "# get the path or directory\n",
        "folder_dir = str(path)+'/MEDIAPIPEinput/'\n",
        "for images in os.listdir(folder_dir):\n",
        " \n",
        "    # check if the image ends with png or jpg or jpeg\n",
        "    if (images.endswith(\".png\") or images.endswith(\".jpg\") or images.endswith(\".jpeg\")):\n",
        "        # display\n",
        "        print(images)"
      ],
      "metadata": {
        "id": "79xoNImGLVMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path"
      ],
      "metadata": {
        "id": "lzos6UZeNq2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.utils.image_dataset_from_directory(\n",
        "  path,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "OVXCLpCENKMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds"
      ],
      "metadata": {
        "id": "sOAIMTU_NwMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "\n",
        "urls = 'https://github.com/1kaiser/Media-Segment-Depth-MLP/releases/download/v0.2/s.zip'\n",
        "data_dir = tf.keras.utils.get_file(origin=urls,\n",
        "                                   fname='s',\n",
        "                                   cache_subdir='/content/biy',\n",
        "                                   archive_format='auto',\n",
        "                                   untar=False,\n",
        "                                   extract=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "metadata": {
        "id": "UpkVRTg_RNtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/biy"
      ],
      "metadata": {
        "id": "CPhcP4p1hx-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir"
      ],
      "metadata": {
        "id": "x7WkVlFGRjDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(data_dir.glob('*/*.png')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "id": "emZOpEFHRf1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import flax.linen as nn\n",
        "import jax.numpy as jnp\n",
        "from jax.random import PRNGKey\n",
        "\n",
        "x = jnp.empty((4, 28, 28, 1)) \n",
        "\n",
        "x.reshape((x.shape[0], -1)).shape\n",
        "\n",
        "class MLP(nn.Module):                              # create a Flax Module dataclass\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, input_points):\n",
        "    # x = x.reshape((x.shape[0], -1))\n",
        "    # x = nn.Dense(128)(x)                           # create inline Flax Module submodules\n",
        "    # x = nn.relu(x)\n",
        "    # x = nn.Dense(1)(x)                 # shape inference\n",
        "    # return x\n",
        "    for i in range(8):\n",
        "      x = nn.Dense(256)(x)\n",
        "      x = nn.relu(x)\n",
        "      x = jnp.concatenate([x, input_points], axis=-1) if i == 4 else x\n",
        "      x = nn.Dense(1)(x)\n",
        "      return x\n",
        "model = MLP()                           # instantiate the MLP model\n",
        "\n",
        "x = jnp.empty((4, 28, 28, 1))                      # generate random data\n",
        "params = model.init(PRNGKey(42), x)[\"params\"]      # initialize the weights\n",
        "y = model.apply({\"params\":params}, x)  "
      ],
      "metadata": {
        "id": "o4MNU3XHpEhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "227DGBDgp5Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positional_encoding_dims = 6  # Number of positional encodings applied\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def positional_encoding(args):\n",
        "    image_height_x_image_width, cha = args.shape\n",
        "    inputs_freq = jax.vmap(lambda x: args * 2.0 ** x)(jnp.arange(positional_encoding_dims))\n",
        "    x = jnp.stack([jnp.sin(inputs_freq), jnp.cos(inputs_freq)])\n",
        "    x = x.swapaxes(0, 2);print(x.shape)\n",
        "    x = x.reshape([image_height_x_image_width, -1])\n",
        "    x = jnp.concatenate([args, x], axis=-1)\n",
        "    return x\n",
        "\n",
        "x = jnp.empty((4, 28, 28, 1))\n",
        "positional_encoding(x.reshape(x.shape[0],-1)).shape"
      ],
      "metadata": {
        "id": "6yyDrzoqrpT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "PATH = '/content/biy/'\n",
        "BATCH_SIZE = 12\n",
        "IMAGE_SIZE = 140\n",
        "\n",
        "def read_train_data():\n",
        "    x_files = [f for f in glob.glob(PATH + \"MEDIAPIPEinput/*.png\", recursive=True)]\n",
        "    y_files = [f for f in glob.glob(PATH + \"annotated_images/*.png\", recursive=True)]\n",
        "\n",
        "    def read_image(x_filename, y_filename):\n",
        "        x_image_string = tf.io.read_file(x_filename)\n",
        "        y_image_string = tf.io.read_file(y_filename)\n",
        "\n",
        "        x_image_decoded = tf.image.decode_jpeg(x_image_string, channels=3)\n",
        "        y_image_decoded = tf.image.decode_jpeg(y_image_string, channels=3)\n",
        "\n",
        "        x_image_resized = tf.image.resize(x_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "        y_image_resized = tf.image.resize(y_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "\n",
        "        x_image_norm = x_image_resized / 255\n",
        "        y_image_norm = y_image_resized / 255\n",
        "\n",
        "        return x_image_norm, y_image_norm\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x_files, y_files))\n",
        "\n",
        "    dataset = dataset.map(read_image).shuffle(1000).batch(BATCH_SIZE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "train_set = read_train_data()\n",
        "for x, y in train_set.as_numpy_iterator():\n",
        "  print(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "Z8UdlS_531XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install -q -U flax\n",
        "import functools\n",
        "from flax.training.train_state import TrainState\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = jnp.ravel(y_true)\n",
        "    y_pred = jnp.ravel(y_pred)\n",
        "    intersection = jnp.sum(y_true * y_pred)\n",
        "    return 2.0 * intersection / (jnp.sum(y_true) + jnp.sum(y_pred) + 1)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "class CustomTrainState(TrainState):\n",
        "    def apply_fn_with_bn(self, *args, is_training, **nargs):\n",
        "        output = self.apply_fn(*args, **nargs,rngs={'dropout': jax.random.PRNGKey(2)})\n",
        "        return output\n",
        "\n",
        "@functools.partial(jax.jit, static_argnums=(3,))\n",
        "def train_step(x, y, train_state, is_training=True):\n",
        "    def loss_fn(params, is_training):\n",
        "        y_pred= train_state.apply_fn_with_bn({\"params\": params}, x, is_training=is_training)\n",
        "        loss = dice_coef_loss(y, y_pred)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    if is_training:\n",
        "        grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "        (loss), grads = grad_fn(train_state.params, True)\n",
        "\n",
        "        train_state = train_state.apply_gradients(grads=grads)\n",
        "    else:\n",
        "        loss = loss_fn(train_state.params, False)\n",
        "\n",
        "    return loss, train_state"
      ],
      "metadata": {
        "id": "OYapBRMtyKdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "unet = MLP(out_dims=10)\n",
        "\n",
        "init_rngs = {'params': jax.random.PRNGKey(0), 'dropout': jax.random.PRNGKey(1)}\n",
        "\n",
        "unet_variables = unet.init(init_rngs, jnp.ones([1, IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
        "\n",
        "optimizer = optax.adam(learning_rate=0.001)\n",
        "\n",
        "train_state = CustomTrainState.create(apply_fn=unet.apply, params=unet_variables[\"params\"], tx=optimizer)\n",
        "\n",
        "\n",
        "for e in range(20):\n",
        "        loss_avg = 0\n",
        "        for x, y in train_set.as_numpy_iterator():\n",
        "            loss, train_state = train_step(x, y, train_state, True)\n",
        "            print(f\"epoch: {e}, loss: {loss:0.2f}\")"
      ],
      "metadata": {
        "id": "xQJtLnKfymB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = jnp.empty((4, 28, 28, 3))\n",
        "c = x[2]\n",
        "c.shape\n",
        "c = c.reshape(-1, c.shape[2])\n",
        "p = positional_encoding(c)\n",
        "print(p.shape)"
      ],
      "metadata": {
        "id": "qH1bBmY0eVy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "x = jnp.empty((4, 28, 28, 1))\n",
        "print(x.shape)\n",
        "\n",
        "def positional_encoding(args):\n",
        "    print(args.shape)\n",
        "    image_height_x_image_width, cha = args.shape\n",
        "    inputs_freq = jax.vmap(lambda x: args * 2.0 ** x)(jnp.arange(6))\n",
        "    x = jnp.stack([jnp.sin(inputs_freq), jnp.cos(inputs_freq)])\n",
        "    x = x.swapaxes(0, 2);print(x.shape)\n",
        "    x = x.reshape([image_height_x_image_width, -1])\n",
        "    x = jnp.concatenate([args, x], axis=-1)\n",
        "    return x\n",
        "\n",
        "    \n",
        "img_list = []\n",
        "for i in range(x.shape[0]):\n",
        "  print(i)\n",
        "  print(x[i].shape)\n",
        "  c = x[i]\n",
        "  c.shape\n",
        "  c = c.reshape(-1, c.shape[2])\n",
        "  p = positional_encoding(c)\n",
        "  img_list.append(p)\n",
        "  print(p.shape)"
      ],
      "metadata": {
        "id": "EB5Rv3cPa1kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape, jnp.array(img_list).shape)"
      ],
      "metadata": {
        "id": "WxgiDRogqsij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**starting here 🔻**"
      ],
      "metadata": {
        "id": "jUx9EzYmw_3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "!python -m pip install -q -U flax\n",
        "import flax.linen as nn\n",
        "from typing import Any\n",
        "import jax\n",
        "from jax import lax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "positional_encoding_dims = 6  # Number of positional encodings applied\n",
        "\n",
        "def positional_encoding(args):\n",
        "    image_height_x_image_width, cha = args.shape\n",
        "    inputs_freq = jax.vmap(lambda x: args * 2.0 ** x)(jnp.arange(positional_encoding_dims))\n",
        "    x = jnp.stack([jnp.sin(inputs_freq), jnp.cos(inputs_freq)])\n",
        "    x = x.swapaxes(0, 2)\n",
        "    x = x.reshape([image_height_x_image_width, -1])\n",
        "    x = jnp.concatenate([args, x], axis=-1)\n",
        "    return x\n",
        "\n",
        "def batch_encoded(args):\n",
        "    img_list = []\n",
        "    for i in range(args.shape[0]):\n",
        "        c = args[i]\n",
        "        c = c.reshape(-1, c.shape[2])\n",
        "        p = positional_encoding(c)\n",
        "        img_list.append(p.reshape(args.shape[1],args.shape[2],p.shape[1]))\n",
        "        x = jnp.array(img_list)\n",
        "    return x\n",
        "\n",
        "apply_positional_encoding = True # Apply posittional encoding to the input or not\n",
        "ndl = 8 # num_dense_layers Number of dense layers in MLP\n",
        "dlw = 256 # dense_layer_width Dimentionality of dense layers' output space \n",
        "\n",
        "##########################################<< MLP MODEL >>#########################################\n",
        "class MLPModel(nn.Module):\n",
        "    dtype: Any = jnp.float32\n",
        "    precision: Any = lax.Precision.DEFAULT\n",
        "    apply_positional_encoding: bool = apply_positional_encoding\n",
        "    @nn.compact\n",
        "    def __call__(self, input_points):\n",
        "      x = batch_encoded(input_points) if self.apply_positional_encoding else input_points\n",
        "      for i in range(ndl):\n",
        "          x = nn.Dense(dlw,dtype=self.dtype,precision=self.precision)(x)\n",
        "          x = nn.relu(x)\n",
        "          x = jnp.concatenate([x, input_points], axis=-1) if i == 4 else x\n",
        "      x = nn.Dense(3, dtype=self.dtype, precision=self.precision)(x)\n",
        "      return x\n",
        "##########################################<< MLP MODEL >>#########################################"
      ],
      "metadata": {
        "id": "GKR8uycsszAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "unet = MLPModel()\n",
        "\n",
        "init_rngs = {'params': jax.random.PRNGKey(0), 'dropout': jax.random.PRNGKey(1)}\n",
        "IMAGE_SIZE = 140\n",
        "unet_variables = unet.init(init_rngs, jnp.ones([7, IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
        "\n",
        "optimizer = optax.adam(learning_rate=0.001)\n",
        "\n",
        "from flax.training.train_state import TrainState\n",
        "\n",
        "class CustomTrainState(TrainState):\n",
        "    def apply_fn_with_bn(self, *args, is_training, **nargs):\n",
        "        output = self.apply_fn(*args, **nargs,rngs={'dropout': jax.random.PRNGKey(2)})\n",
        "        return output\n",
        "\n",
        "train_state = CustomTrainState.create(apply_fn=unet.apply, params=unet_variables[\"params\"], tx=optimizer)"
      ],
      "metadata": {
        "id": "dYWCevDSuVVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jax.tree_util import tree_structure\n",
        "print(tree_structure(train_state))"
      ],
      "metadata": {
        "id": "E95IUYDTNHC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = 'https://github.com/1kaiser/Media-Segment-Depth-MLP/releases/download/v0.2/s.zip'\n",
        "data_dir = tf.keras.utils.get_file(origin=urls,\n",
        "                                   fname='s',\n",
        "                                   cache_subdir='/content/biy',\n",
        "                                   archive_format='auto',\n",
        "                                   untar=False,\n",
        "                                   extract=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "metadata": {
        "id": "cMAduDgwPfaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "\n",
        "@functools.partial(jax.jit, static_argnums=(3,))\n",
        "def train_step(x, y, train_state, is_training=True):\n",
        "    def loss_fn(params, is_training):\n",
        "        y_pred= train_state.apply_fn_with_bn({\"params\": params}, x, is_training=is_training)\n",
        "        loss = dice_coef_loss(y, y_pred)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    if is_training:\n",
        "        grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "        loss, grads = grad_fn(train_state.params, True)\n",
        "\n",
        "        train_state = train_state.apply_gradients(grads=grads)\n",
        "    else:\n",
        "        loss = loss_fn(train_state.params, False)\n",
        "\n",
        "    return loss, train_state\n",
        "\n",
        "PATH = '/content/biy/'\n",
        "BATCH_SIZE = 12\n",
        "IMAGE_SIZE = 140\n",
        "\n",
        "def read_train_data():\n",
        "    x_files = [f for f in glob.glob(PATH + \"MEDIAPIPEinput/*.png\", recursive=True)]\n",
        "    y_files = [f for f in glob.glob(PATH + \"annotated_images/*.png\", recursive=True)]\n",
        "\n",
        "    def read_image(x_filename, y_filename):\n",
        "        x_image_string = tf.io.read_file(x_filename)\n",
        "        y_image_string = tf.io.read_file(y_filename)\n",
        "\n",
        "        x_image_decoded = tf.image.decode_png(x_image_string, channels=3)\n",
        "        y_image_decoded = tf.image.decode_png(y_image_string, channels=3)\n",
        "\n",
        "        x_image_resized = tf.image.resize(x_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "        y_image_resized = tf.image.resize(y_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "\n",
        "        x_image_norm = x_image_resized / 255\n",
        "        y_image_norm = y_image_resized / 255\n",
        "\n",
        "        return x_image_norm, y_image_norm\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x_files, y_files))\n",
        "\n",
        "    dataset = dataset.map(read_image).shuffle(1000).batch(BATCH_SIZE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4k8J2h_QwMtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = read_train_data()\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = jnp.ravel(y_true)\n",
        "    y_pred = jnp.ravel(y_pred)\n",
        "    intersection = jnp.sum(y_true * y_pred)\n",
        "    return 2.0 * intersection / (jnp.sum(y_true) + jnp.sum(y_pred) + 1)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "for e in range(20):\n",
        "        loss_avg = 0\n",
        "        for x, y in train_set.as_numpy_iterator():\n",
        "            loss, train_state = train_step(x, y, train_state, True)\n",
        "            print(f\"epoch: {e}, loss: {loss:0.2f}\")"
      ],
      "metadata": {
        "id": "Jefe9HxKxO-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**ensemble test**"
      ],
      "metadata": {
        "id": "k1KLX-FNqSFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urls = 'https://github.com/1kaiser/Media-Segment-Depth-MLP/releases/download/v0.2/s.zip'\n",
        "data_dir = tf.keras.utils.get_file(origin=urls,\n",
        "                                   fname='s',\n",
        "                                   cache_subdir='/content/biy',\n",
        "                                   archive_format='auto',\n",
        "                                   untar=False,\n",
        "                                   extract=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "metadata": {
        "id": "1dyRUFLWq0hN"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "!python -m pip install -q -U flax\n",
        "from typing import Any\n",
        "import jax\n",
        "from jax import lax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state, common_utils\n",
        "import functools\n",
        "\n",
        "positional_encoding_dims = 6  # Number of positional encodings applied\n",
        "\n",
        "def positional_encoding(args):\n",
        "    image_height_x_image_width, cha = args.shape\n",
        "    inputs_freq = jax.vmap(lambda x: args * 2.0 ** x)(jnp.arange(positional_encoding_dims))\n",
        "    x = jnp.stack([jnp.sin(inputs_freq), jnp.cos(inputs_freq)])\n",
        "    x = x.swapaxes(0, 2)\n",
        "    x = x.reshape([image_height_x_image_width, -1])\n",
        "    x = jnp.concatenate([args, x], axis=-1)\n",
        "    return x\n",
        "\n",
        "def batch_encoded(args):\n",
        "    img_list = []\n",
        "    for i in range(args.shape[0]):\n",
        "        c = args[i]\n",
        "        c = c.reshape(-1, c.shape[2])\n",
        "        p = positional_encoding(c)\n",
        "        img_list.append(p.reshape(args.shape[1],args.shape[2],p.shape[1]))\n",
        "        x = jnp.array(img_list)\n",
        "    return x\n",
        "\n",
        "apply_positional_encoding = True # Apply posittional encoding to the input or not\n",
        "ndl = 8 # num_dense_layers Number of dense layers in MLP\n",
        "dlw = 256 # dense_layer_width Dimentionality of dense layers' output space \n",
        "\n",
        "##########################################<< MLP MODEL >>#########################################\n",
        "class MLPModel(nn.Module):\n",
        "    dtype: Any = jnp.float32\n",
        "    precision: Any = lax.Precision.DEFAULT\n",
        "    apply_positional_encoding: bool = apply_positional_encoding\n",
        "    @nn.compact\n",
        "    def __call__(self, input_points):\n",
        "      x = batch_encoded(input_points) if self.apply_positional_encoding else input_points\n",
        "      for i in range(ndl):\n",
        "          x = nn.Dense(dlw,dtype=self.dtype,precision=self.precision)(x)\n",
        "          x = nn.relu(x)\n",
        "          x = jnp.concatenate([x, input_points], axis=-1) if i == 4 else x\n",
        "      x = nn.Dense(3, dtype=self.dtype, precision=self.precision)(x)\n",
        "      return x\n",
        "##########################################<< MLP MODEL >>#########################################\n",
        "\n",
        "@functools.partial(jax.pmap, static_broadcasted_argnums=(1, 2))\n",
        "def Create_train_state(r_key, shape, learning_rate ):\n",
        "    print(shape)\n",
        "    model = MLPModel()\n",
        "    variables = model.init(r_key, jnp.ones(shape)) \n",
        "    optimizer = optax.adam(learning_rate) \n",
        "    return train_state.TrainState.create(\n",
        "        apply_fn = model.apply,\n",
        "        tx=optimizer,\n",
        "        params=variables['params']\n",
        "    )\n",
        "\n",
        "# learning_rate = 1e-4\n",
        "# batch_size_no = 64\n",
        "\n",
        "# model = MLPModel() # Instantiate the Model"
      ],
      "metadata": {
        "id": "V7oQoK4fqWXA"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@functools.partial(jax.pmap, axis_name='ensemble')\n",
        "def apply_model(state, batch: jnp.asarray):\n",
        "  image, label = batch\n",
        "  def loss_fn(params):\n",
        "    logits = MLPModel().apply({'params': params}, image)\n",
        "    loss =  image_difference_loss(logits, label);\n",
        "    return loss, logits\n",
        "\n",
        "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  (loss, logits), grads = grad_fn(state.params)\n",
        "  return grads, loss\n",
        "\n",
        "@jax.pmap\n",
        "def update_model(state, grads):\n",
        "  return state.apply_gradients(grads=grads)"
      ],
      "metadata": {
        "id": "eOKwXeVSqWXB"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(state, train_ds, batch_size, rng):\n",
        "  train_ds_size = len(train_ds['image'])\n",
        "  steps_per_epoch = train_ds_size // batch_size\n",
        "\n",
        "  perms = jax.random.permutation(rng, len(train_ds['image']))\n",
        "  perms = perms[:steps_per_epoch * batch_size]\n",
        "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
        "\n",
        "  epoch_loss = []\n",
        "\n",
        "  for perm in perms:\n",
        "    batch_images = jax_utils.replicate(train_ds['image'][perm, ...])\n",
        "    batch_labels = jax_utils.replicate(train_ds['label'][perm, ...])\n",
        "    grads, loss = apply_model(state, batch_images, batch_labels)\n",
        "    state = update_model(state, grads)\n",
        "    epoch_loss.append(jax_utils.unreplicate(loss))\n",
        "  train_loss = np.mean(epoch_loss)\n",
        "  return state, train_loss"
      ],
      "metadata": {
        "id": "WfDPh1VVqWXB"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PATH = '/content/biy/'\n",
        "BATCH_SIZE = 1\n",
        "IMAGE_SIZE = 140\n",
        "\n",
        "def read_train_data():\n",
        "    x_files = [f for f in glob.glob(PATH + \"MEDIAPIPEinput/*.png\", recursive=True)]\n",
        "    y_files = [f for f in glob.glob(PATH + \"annotated_images/*.png\", recursive=True)]\n",
        "\n",
        "    def read_image(x_filename, y_filename):\n",
        "        x_image_string = tf.io.read_file(x_filename)\n",
        "        y_image_string = tf.io.read_file(y_filename)\n",
        "\n",
        "        x_image_decoded = tf.image.decode_png(x_image_string, channels=3)\n",
        "        y_image_decoded = tf.image.decode_png(y_image_string, channels=3)\n",
        "\n",
        "        x_image_resized = tf.image.resize(x_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "        y_image_resized = tf.image.resize(y_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "\n",
        "        x_image_norm = x_image_resized / 255\n",
        "        y_image_norm = y_image_resized / 255\n",
        "\n",
        "        return x_image_norm, y_image_norm\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x_files, y_files))\n",
        "\n",
        "    dataset = dataset.map(read_image).shuffle(1000).batch(BATCH_SIZE)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "Y0c9bZwkq4uW"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = read_train_data()\n"
      ],
      "metadata": {
        "id": "i-TG5DE_q9qo"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################## to load the data in batches as mentioned single batch of images with already provided sizes \n",
        "import jax\n",
        "from jax import random\n",
        "\n",
        "newsize = (140,140) #(260, 260) # /.... 233 * 454\n",
        "batch_size = 10\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def imageGRAY(argv):\n",
        "    im = Image.open(argv).convert('L')\n",
        "    tvt, tvu = jnp.asarray(im.resize(newsize)),jnp.asarray(im.resize(newsize)).reshape(-1,1)\n",
        "    return tvt, tvu\n",
        "def imageRGB(argv):\n",
        "    im = Image.open(argv)\n",
        "    tvt, tvu = jnp.asarray(im.resize(newsize)),jnp.asarray(im.resize(newsize)).reshape(-1,3)\n",
        "    return tvt, tvu\n",
        "\n",
        "x_image_dir = r'/content/biy/MEDIAPIPEinput/'\n",
        "y_image_dir = r'/content/biy/annotated_images/'\n",
        "\n",
        "#############################################################################\n",
        "bandend = [\"c\",\".png\", \"b02\"]\n",
        "expression_b2 = bandend[1]\n",
        "x_total_images =  [f for f in os.listdir(x_image_dir) if f.__contains__(expression_b2)]\n",
        "x_total_images.sort()\n",
        "x_total_images_path = [os.path.join(x_image_dir, i) for i in x_total_images if i != 'outputs']\n",
        "no_of_batches = int(len(x_total_images_path)/batch_size)\n",
        "\n",
        "\n",
        "y_total_images =  [f for f in os.listdir(y_image_dir) if f.__contains__(expression_b2)]\n",
        "y_total_images.sort()\n",
        "y_total_images_path = [os.path.join(y_image_dir, i) for i in y_total_images if i != 'outputs']\n",
        "\n",
        "\n",
        "######################################## making 8 array of input for each device >>>\n",
        "def batchedimages(total_images_path, image_locations):\n",
        "  RGB8 = jnp.asarray((imageRGB(total_images_path[image_locations[0]])[0]))\n",
        "  return RGB8\n",
        "\n",
        "\n",
        "def data_stream():\n",
        "  key = random.PRNGKey(0)\n",
        "  perm = random.permutation(key, len(total_images_path))\n",
        "  x_image_list = []\n",
        "  y_image_list = []\n",
        "\n",
        "  for i in range(no_of_batches):\n",
        "    batch_idx = perm[i * batch_size : (i + 1) * batch_size]; #print(batch_idx)\n",
        "    x_image_list.append(batchedimages(x_total_images_path, batch_idx))\n",
        "    y_image_list.append(batchedimages(y_total_images_path, batch_idx))\n",
        "  yield jnp.array(x_image_list),jnp.array(y_image_list)\n",
        "\n",
        "batches = data_stream()  \n"
      ],
      "metadata": {
        "id": "JUbPb0MMR7Xl"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_ds, y_train_ds = next(data_stream())\n",
        "print(x_train_ds.shape, y_train_ds.shape)"
      ],
      "metadata": {
        "id": "Kut8CGgKcMKf",
        "outputId": "73ea01ac-41c4-4728-ac3e-3d4ec059c8b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(101, 140, 140, 3) (101, 140, 140, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_ds[0].shape\n"
      ],
      "metadata": {
        "id": "L_3E7rPlfBGN",
        "outputId": "abc192d8-8f31-4aa8-9d64-fced1a00ad8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140, 140, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as onp\n",
        "img = onp.array(x_train_ds[0])\n",
        "cv2_imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "g1eZPtjUfNTQ",
        "outputId": "45dce4b7-36a3-4d98-f820-7e2ab59cf024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=140x140 at 0x7F996876CFA0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_ds, y_train_ds = next(data_stream())\n",
        "print(x_train_ds.shape, y_train_ds.shape)"
      ],
      "metadata": {
        "id": "QRasLuCvZDOX",
        "outputId": "dd1b250f-d112-45ee-832c-5e5d6733bc74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(140, 140, 3) (140, 140, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 1024\n",
        "x_files = [f for f in glob.glob(PATH + \"MEDIAPIPEinput/*.png\", recursive=True)]\n",
        "x_image_string = tf.io.read_file(x_files[0])\n",
        "x_image_decoded = tf.image.decode_png(x_image_string, channels=3)\n",
        "img = tf.image.resize(x_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(cv2.cvtColor(img.numpy(), cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "66Cyn_6-_YKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b31CD-m-_kEI",
        "outputId": "45f0885d-151d-4018-ce39-9c16656c5245"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, test_ds = get_datasets()\n",
        "# test_ds = jax_utils.replicate(test_ds)\n",
        "rng = jax.random.PRNGKey(0)\n",
        "\n",
        "rng, init_rng = jax.random.split(rng)\n",
        "\n",
        "HxW, Channels = next(batches)[0].shape\n",
        "state = create_train_state(jax.random.split(init_rng, jax.device_count()),(HxW, Channels),learning_rate)\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  rng, input_rng = jax.random.split(rng)\n",
        "  state, train_loss = train_epoch(state, train_ds, batch_size, input_rng)\n",
        "\n",
        "  # _, test_loss = jax_utils.unreplicate(apply_model(state, test_ds['image'], test_ds['label']))\n",
        "\n",
        "  logging.info('epoch:% 3d, train_loss: %.4f ' % (epoch, train_loss))"
      ],
      "metadata": {
        "id": "S6qpssQEqWXB",
        "outputId": "2d2b7f0f-88c0-4668-9171-d045b949c969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-6b80a54dd49a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# test_ds = jax_utils.replicate(test_ds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_rng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_datasets' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same as before, but using @pad_shard_unshard decorator\n",
        "\n",
        "# manually padding\n",
        "# => precise & allows for data parallelism\n",
        "\n",
        "@jax.pmap\n",
        "def get_preds(variables, inputs):\n",
        "  print('retrigger compilation', inputs.shape)\n",
        "  return model.apply(variables, inputs)\n",
        "\n",
        "ds = tfds.load(dataset_name, split=tfds.split_for_jax_process('test'))\n",
        "per_host_batch_size = per_device_batch_size * jax.local_device_count()\n",
        "ds = ds.batch(per_host_batch_size, drop_remainder=False)\n",
        "\n",
        "correct = total = 0\n",
        "for batch in ds.as_numpy_iterator():\n",
        "  preds = flax.jax_utils.pad_shard_unpad(get_preds)(\n",
        "      vs, batch['image'], min_device_batch=per_device_batch_size)\n",
        "  total += len(batch['image'])\n",
        "  correct += (batch['label'] == preds.argmax(axis=-1)).sum()\n",
        "\n",
        "correct = correct.item()\n",
        "correct, total, correct / total"
      ],
      "metadata": {
        "id": "slrmR8coqWXC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}